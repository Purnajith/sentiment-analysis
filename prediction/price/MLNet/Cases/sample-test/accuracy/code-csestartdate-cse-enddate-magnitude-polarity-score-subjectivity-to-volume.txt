|     Trainer                             RSquared Absolute-loss Squared-loss RMS-loss  Duration #Iteration      |
|1    SdcaRegression                       -1.1454       8571.15 187295308.56 12658.23       1.3          1      |
|2    LightGbmRegression                   -2.5790      11649.38 290588503.97 16369.40       0.7          2      |
|3    FastTreeRegression                   -2.2566      11393.39 269095045.33 15493.01       1.0          3      |
|4    FastTreeTweedieRegression            -0.4921       8129.79 225606591.18 13653.88       1.0          4      |
|5    FastForestRegression                 -0.9816       9369.79 215458666.97 13530.75       1.0          5      |
|6    LbfgsPoissonRegression               -2.3519       9118.31 293543675.97 15777.11       0.5          6      |
|7    OnlineGradientDescentRegression      -0.7757       9304.82 205552168.48 12918.63       0.5          7      |
|8    OlsRegression                        -1.5378       8924.94 194838095.85 13057.01       0.5          8      |
|9    FastTreeTweedieRegression            -0.6937       9752.83 319455933.83 16087.05       0.6          9      |
|10   FastForestRegression                 -2.0346       7682.06 184021001.73 12516.79       0.9         10      |
The weights/bias contain invalid values (NaN or Infinite). Potential causes: high learning rates, no normalization, high initial weights, etc.
|11   FastTreeTweedieRegression            -0.3580       8845.57 232196283.87 13543.25       0.7         11      |
|12   FastForestRegression                  0.0000          0.00         0.00     0.00       0.6         12      |
|13   OnlineGradientDescentRegression      -0.6064       9373.93 312400334.28 15847.91       0.5         13      |
|14   FastTreeTweedieRegression            -0.6960       9763.87 319641270.93 16093.24       0.8         14      |
|15   FastForestRegression                 -0.9741       9386.50 213442581.63 13478.34       0.7         15      |
|16   OnlineGradientDescentRegression      -0.3891       8484.64 289380913.34 15103.27       0.6         16      |
|17   FastTreeTweedieRegression            -0.6968       9766.51 319722106.54 16095.68       0.6         17      |
|18   FastForestRegression                 -0.9531       9450.32 217700049.17 13591.44       3.2         18      |
|19   OnlineGradientDescentRegression      -0.3819       8462.23 290349467.53 15105.84       0.5         19      |
|20   FastTreeTweedieRegression            -6.7702       7284.97 218388779.52 13133.92       1.0         20      |
|21   FastForestRegression                 -1.0931       7992.67 175671495.37 12035.49       1.3         21      |
|22   OnlineGradientDescentRegression      -0.3210       8241.47 278667747.94 14790.30       0.5         22      |
|23   FastTreeTweedieRegression            -0.5594       9152.88 307525090.84 15691.88       0.8         23      |
|24   FastForestRegression                 -0.9816       9369.79 215458666.97 13530.75       1.1         24      |
|25   OnlineGradientDescentRegression      -0.3072       8278.52 277874723.56 14745.47       0.5         25      |
|26   FastTreeTweedieRegression            -0.8283       9894.30 255697828.19 14544.30       0.8         26      |
|27   FastForestRegression                 -1.2697       7976.70 177670241.63 12245.26       3.5         27      |
|28   OnlineGradientDescentRegression      -0.4723       8765.27 298870741.57 15410.23       0.5         28      |
|29   FastTreeTweedieRegression            -0.6974       9769.39 319778233.91 16097.49       0.7         29      |
|30   FastForestRegression                 -1.3410       7987.62 177467720.31 12212.64      23.2         30      |
The weights/bias contain invalid values (NaN or Infinite). Potential causes: high learning rates, no normalization, high initial weights, etc.
|31   FastTreeTweedieRegression            -5.7252       7027.16 186238222.39 12383.38       5.1         31      |
|32   FastForestRegression                 -0.1703       5271.08 125083675.55  7238.95       0.7         32      |
|33   OnlineGradientDescentRegression     -116239436903276000000000000000000000000.0000 19653383190687400000000.00 2131996731667010000000000000000000000000000000.00 20735179763183000000000.00       0.5         33|
|34   FastTreeTweedieRegression            -0.6954       9760.34 319601935.06 16091.79       0.7         34      |
|35   FastForestRegression                 -0.9741       9386.50 213442581.63 13478.34       0.8         35      |
The weights/bias contain invalid values (NaN or Infinite). Potential causes: high learning rates, no normalization, high initial weights, etc.

===============================================Experiment Results=================================================
------------------------------------------------------------------------------------------------------------------
|                                                     Summary                                                    |
------------------------------------------------------------------------------------------------------------------
|ML Task: regression                                                                                             |
|Dataset: C:\Users\purna\source\repos\Purnajith\sentiment-analysis\prediction\price\data2\arrangedData.csv       |
|Label : volume                                                                                                  |
|Total experiment time : 59.1552146 Secs                                                                         |
|Total number of models explored: 38                                                                             |
------------------------------------------------------------------------------------------------------------------

|                                              Top 5 models explored                                             |
------------------------------------------------------------------------------------------------------------------
|     Trainer                             RSquared Absolute-loss Squared-loss RMS-loss  Duration #Iteration      |
|1    FastForestRegression                  0.0000          0.00         0.00     0.00       0.6          1      |
|2    FastForestRegression                 -0.1703       5271.08 125083675.55  7238.95       0.7          2      |
|3    OnlineGradientDescentRegression      -0.3072       8278.52 277874723.56 14745.47       0.5          3      |
|4    OnlineGradientDescentRegression      -0.3210       8241.47 278667747.94 14790.30       0.5          4      |
|5    FastTreeTweedieRegression            -0.3580       8845.57 232196283.87 13543.25       0.7          5      |
------------------------------------------------------------------------------------------------------------------